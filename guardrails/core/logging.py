"""
ScamAware Jersey Guardrails - Structured Logging Module
========================================================

This module provides JSON-structured logging for the Guardrails service,
enabling better observability, log aggregation, and debugging capabilities.

Features:
---------
- JSON log formatting using python-json-logger (production)
- Human-readable formatting (development)
- Request ID injection for request tracing
- Environment-aware configuration
- Configurable log levels via environment variables

Usage:
------
    from core.logging import configure_logging, get_logger, set_request_id

    # Initialize logging on application startup
    configure_logging()

    # Get a logger for your module
    logger = get_logger(__name__)

    # Set request ID for the current request context
    set_request_id("uuid-here")

    # Log messages (extra fields are automatically included)
    logger.info("Request processed", extra={"endpoint": "/validate"})

Environment Variables:
----------------------
- LOG_LEVEL: DEBUG, INFO, WARNING, ERROR, CRITICAL (default: INFO)
- LOG_FORMAT: json, text (default: text for development)
- ENVIRONMENT: development, staging, production (affects default LOG_FORMAT)

================================================================================
CRITICAL PRIVACY NOTICE - READ BEFORE MODIFYING THIS FILE
================================================================================

***** NEVER LOG THE FOLLOWING *****

1. USER MESSAGES/CONVERSATIONS
   - Do NOT log the content of user messages or AI responses
   - Do NOT log conversation history or session content
   - These may contain sensitive personal information

2. IP ADDRESSES
   - Do NOT log raw IP addresses
   - If IP tracking is needed, use hashed/anonymized values only
   - Use the hash_sensitive_data() helper function

3. PERSONALLY IDENTIFIABLE INFORMATION (PII)
   - Do NOT log names, email addresses, phone numbers
   - Do NOT log financial information (card numbers, bank details)
   - Do NOT log Jersey ID numbers or any government identifiers
   - Do NOT log passwords, PINs, or authentication tokens

4. REQUEST/RESPONSE BODIES
   - Do NOT log full request bodies (may contain user messages)
   - Do NOT log full response bodies (may contain sensitive advice)
   - Only log sanitized metadata (content length, status code, etc.)

ACCEPTABLE TO LOG:
- Request IDs (for tracing)
- Timestamps
- Log levels
- Service name
- Endpoint paths (not query parameters with sensitive data)
- HTTP status codes
- Response times
- Error types (not full stack traces with user data)
- Content lengths (not content itself)

Violations of these guidelines may breach GDPR and Jersey data protection laws.
================================================================================
"""

import hashlib
import logging
import os
import sys
from contextvars import ContextVar
from datetime import datetime, timezone
from typing import Any

from pythonjsonlogger import jsonlogger

# =============================================================================
# Constants
# =============================================================================

SERVICE_NAME = "scamaware-guardrails"
DEFAULT_LOG_LEVEL = "INFO"
DEFAULT_LOG_FORMAT = "text"

# Context variable for request ID (thread-safe for async)
_request_id_ctx: ContextVar[str | None] = ContextVar("request_id", default=None)

# =============================================================================
# Request ID Management
# =============================================================================


def set_request_id(request_id: str | None) -> None:
    """
    Set the request ID for the current context.

    This should be called at the start of each request to enable
    request tracing across all log messages.

    Args:
        request_id: The unique identifier for the current request.
                   Typically a UUID generated by middleware.
    """
    _request_id_ctx.set(request_id)


def get_request_id() -> str | None:
    """
    Get the request ID for the current context.

    Returns:
        The current request ID, or None if not set.
    """
    return _request_id_ctx.get()


def clear_request_id() -> None:
    """
    Clear the request ID for the current context.

    This should be called at the end of each request to clean up.
    """
    _request_id_ctx.set(None)


# =============================================================================
# Sensitive Data Helpers
# =============================================================================


def hash_sensitive_data(data: str, salt: str = "") -> str:
    """
    Hash sensitive data for logging purposes.

    Use this function if you need to log something for tracking purposes
    but cannot log the actual value (e.g., IP addresses for rate limiting).

    IMPORTANT: This is a one-way hash. The original value cannot be recovered.
    Only use this when you need to correlate events without exposing PII.

    Args:
        data: The sensitive data to hash.
        salt: Optional salt for additional security.

    Returns:
        A truncated SHA-256 hash (first 16 characters).

    Example:
        # NEVER log raw IP addresses - use this instead
        logger.info("Rate limited", extra={"client_hash": hash_sensitive_data(ip_address)})
    """
    combined = f"{salt}{data}"
    full_hash = hashlib.sha256(combined.encode()).hexdigest()
    return full_hash[:16]  # Truncate for readability


# =============================================================================
# Custom JSON Formatter
# =============================================================================


class StructuredJsonFormatter(jsonlogger.JsonFormatter):
    """
    Custom JSON formatter that includes standard fields for all log entries.

    Output format:
    {
        "timestamp": "2024-01-23T12:00:00.000Z",
        "level": "INFO",
        "message": "Request processed",
        "request_id": "uuid-here",
        "service": "scamaware-guardrails",
        "logger": "module.name",
        "extra_field": "value"
    }
    """

    def add_fields(
        self,
        log_record: dict[str, Any],
        record: logging.LogRecord,
        message_dict: dict[str, Any],
    ) -> None:
        """
        Add custom fields to every log record.

        This method is called by python-json-logger to customize the output.
        """
        super().add_fields(log_record, record, message_dict)

        # Add ISO 8601 timestamp with milliseconds in UTC
        log_record["timestamp"] = datetime.now(timezone.utc).strftime(
            "%Y-%m-%dT%H:%M:%S.%f"
        )[:-3] + "Z"

        # Normalize level name to uppercase
        log_record["level"] = record.levelname.upper()

        # Add service identifier
        log_record["service"] = SERVICE_NAME

        # Add logger name for source identification
        log_record["logger"] = record.name

        # Inject request ID if available (for request tracing)
        request_id = get_request_id()
        if request_id:
            log_record["request_id"] = request_id

        # Ensure 'message' field is present and positioned correctly
        if "message" not in log_record:
            log_record["message"] = record.getMessage()

        # Reorder fields for consistent output (timestamp first, then level, etc.)
        ordered_fields = ["timestamp", "level", "message", "request_id", "service", "logger"]
        reordered = {}
        for field in ordered_fields:
            if field in log_record:
                reordered[field] = log_record.pop(field)
        # Add remaining fields after the standard ones
        reordered.update(log_record)
        log_record.clear()
        log_record.update(reordered)


# =============================================================================
# Human-Readable Formatter (Development)
# =============================================================================


class DevelopmentFormatter(logging.Formatter):
    """
    Human-readable formatter for development environments.

    Output format:
    2024-01-23 12:00:00.123 | INFO     | module.name | [req-id] Message here
    """

    # ANSI color codes for terminal output
    COLORS = {
        "DEBUG": "\033[36m",     # Cyan
        "INFO": "\033[32m",      # Green
        "WARNING": "\033[33m",   # Yellow
        "ERROR": "\033[31m",     # Red
        "CRITICAL": "\033[35m",  # Magenta
    }
    RESET = "\033[0m"

    def format(self, record: logging.LogRecord) -> str:
        """Format log record for human readability."""
        # Get timestamp
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S.%f")[:-3]

        # Get level with color
        level = record.levelname
        color = self.COLORS.get(level, "")
        colored_level = f"{color}{level:8}{self.RESET}"

        # Get request ID if available
        request_id = get_request_id()
        request_id_str = f"[{request_id[:8]}] " if request_id else ""

        # Get the message
        message = record.getMessage()

        # Format extra fields if any
        extra_fields = ""
        # Check for extra fields added via the 'extra' parameter
        standard_attrs = {
            "name", "msg", "args", "created", "filename", "funcName",
            "levelname", "levelno", "lineno", "module", "msecs",
            "pathname", "process", "processName", "relativeCreated",
            "stack_info", "exc_info", "exc_text", "thread", "threadName",
            "taskName", "message",
        }
        extras = {
            k: v for k, v in record.__dict__.items()
            if k not in standard_attrs and not k.startswith("_")
        }
        if extras:
            extra_fields = " | " + " ".join(f"{k}={v}" for k, v in extras.items())

        # Build the final formatted string
        formatted = f"{timestamp} | {colored_level} | {record.name:20} | {request_id_str}{message}{extra_fields}"

        # Add exception info if present
        if record.exc_info:
            formatted += "\n" + self.formatException(record.exc_info)

        return formatted


# =============================================================================
# Sensitive Data Filter
# =============================================================================


class SensitiveDataFilter(logging.Filter):
    """
    Logging filter to prevent accidental logging of sensitive data.

    This filter acts as a safety net to catch common mistakes.
    It checks log records for potentially sensitive field names
    and masks their values.

    IMPORTANT: This is a last line of defense. Developers should
    NEVER attempt to log sensitive data in the first place.
    """

    # Field names that should never contain actual data in logs
    SENSITIVE_FIELDS = {
        "password", "passwd", "pwd", "secret", "token", "api_key",
        "apikey", "auth", "authorization", "bearer", "credential",
        "credit_card", "card_number", "cvv", "pin", "ssn", "ip_address",
        "ip", "email", "phone", "address", "user_message", "message_content",
        "conversation", "chat_history", "response_content", "ai_response",
    }

    def filter(self, record: logging.LogRecord) -> bool:
        """
        Filter log records to mask sensitive data.

        Returns True to allow the record (after masking), never blocks records.

        PRIVACY WARNING: This filter masks sensitive fields but developers
        should NEVER attempt to log sensitive data. This is only a safety net.
        """
        # Check all attributes in the record
        for attr_name in dir(record):
            if attr_name.startswith("_"):
                continue

            # Check if attribute name suggests sensitive data
            attr_lower = attr_name.lower()
            for sensitive in self.SENSITIVE_FIELDS:
                if sensitive in attr_lower:
                    # Mask the sensitive value
                    setattr(record, attr_name, "[REDACTED]")
                    break

        return True  # Always allow the record (after masking)


# =============================================================================
# Logger Configuration
# =============================================================================


def configure_logging(
    log_level: str | None = None,
    log_format: str | None = None,
    environment: str | None = None,
) -> None:
    """
    Configure structured logging for the application.

    This function should be called once during application startup,
    before any logging is performed.

    Args:
        log_level: Override log level (DEBUG, INFO, WARNING, ERROR, CRITICAL).
                  Defaults to LOG_LEVEL env var or INFO.
        log_format: Override log format (json, text).
                   Defaults to LOG_FORMAT env var or 'text' for dev, 'json' for prod.
        environment: Override environment (development, staging, production).
                    Defaults to ENVIRONMENT env var or 'development'.

    Example:
        # In main.py startup
        from core.logging import configure_logging
        configure_logging()

        # Or with explicit configuration
        configure_logging(log_level="DEBUG", log_format="text")
    """
    # Determine configuration from environment or parameters
    env = environment or os.getenv("ENVIRONMENT", "development")
    level_str = log_level or os.getenv("LOG_LEVEL", DEFAULT_LOG_LEVEL)
    format_str = log_format or os.getenv("LOG_FORMAT")

    # Default format based on environment
    if format_str is None:
        format_str = "json" if env == "production" else "text"

    # Convert level string to logging constant
    level = getattr(logging, level_str.upper(), logging.INFO)

    # Get the root logger
    root_logger = logging.getLogger()
    root_logger.setLevel(level)

    # Remove any existing handlers
    for handler in root_logger.handlers[:]:
        root_logger.removeHandler(handler)

    # Create console handler
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(level)

    # Add sensitive data filter
    console_handler.addFilter(SensitiveDataFilter())

    # Set formatter based on format preference
    if format_str.lower() == "json":
        formatter = StructuredJsonFormatter()
    else:
        formatter = DevelopmentFormatter()

    console_handler.setFormatter(formatter)
    root_logger.addHandler(console_handler)

    # Suppress noisy third-party loggers
    logging.getLogger("uvicorn.access").setLevel(logging.WARNING)
    logging.getLogger("httpx").setLevel(logging.WARNING)
    logging.getLogger("httpcore").setLevel(logging.WARNING)

    # Log initialization (this will use the new format)
    logger = get_logger(__name__)
    logger.info(
        "Logging configured",
        extra={
            "log_level": level_str.upper(),
            "log_format": format_str.lower(),
            "environment": env,
        }
    )


def get_logger(name: str) -> logging.Logger:
    """
    Get a logger instance for the specified module.

    This is a convenience function that wraps logging.getLogger()
    but ensures consistent behavior across the application.

    Args:
        name: The logger name, typically __name__ of the calling module.

    Returns:
        A configured logging.Logger instance.

    Example:
        from core.logging import get_logger
        logger = get_logger(__name__)
        logger.info("Processing request", extra={"endpoint": "/validate"})
    """
    return logging.getLogger(name)


# =============================================================================
# FastAPI Integration Helpers
# =============================================================================


def create_request_context_middleware():
    """
    Create a FastAPI middleware for request ID injection.

    This middleware:
    1. Extracts or generates a request ID
    2. Sets it in the context for logging
    3. Clears it after the request completes

    Returns:
        An async middleware function for FastAPI.

    Usage:
        from core.logging import create_request_context_middleware
        app.middleware("http")(create_request_context_middleware())
    """
    import uuid

    async def request_context_middleware(request, call_next):
        """Middleware to set request ID context for logging."""
        # Try to get request ID from header, or generate a new one
        request_id = request.headers.get("X-Request-ID") or str(uuid.uuid4())

        # Set the request ID in context
        set_request_id(request_id)

        try:
            # Process the request
            response = await call_next(request)

            # Add request ID to response headers for tracing
            response.headers["X-Request-ID"] = request_id

            return response
        finally:
            # Always clear the request ID after the request
            clear_request_id()

    return request_context_middleware


# =============================================================================
# Module Exports
# =============================================================================

__all__ = [
    "configure_logging",
    "get_logger",
    "set_request_id",
    "get_request_id",
    "clear_request_id",
    "hash_sensitive_data",
    "create_request_context_middleware",
    "SensitiveDataFilter",
    "StructuredJsonFormatter",
    "DevelopmentFormatter",
]
